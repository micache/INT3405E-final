{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T10:20:36.754382Z",
     "iopub.status.busy": "2024-12-07T10:20:36.753977Z",
     "iopub.status.idle": "2024-12-07T10:20:40.712342Z",
     "shell.execute_reply": "2024-12-07T10:20:40.711200Z",
     "shell.execute_reply.started": "2024-12-07T10:20:36.754345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "\n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    season_cols = [col for col in df.columns if 'Season' in col]\n",
    "    df = df.drop(season_cols, axis=1) \n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [00:33<00:00, 29.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 11.4 s, total: 2min 27s\n",
      "Wall time: 33.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_train = pd.read_csv('./kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "raw_test = pd.read_csv('./kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('./kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "train_ts = load_time_series(\"./kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"./kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "train_ts = train_ts.astype({col: 'float32' for col in train_ts.select_dtypes(include='float64').columns})\n",
    "test_ts = test_ts.astype({col: 'float32' for col in test_ts.select_dtypes(include='float64').columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T10:20:43.325587Z",
     "iopub.status.busy": "2024-12-07T10:20:43.325034Z",
     "iopub.status.idle": "2024-12-07T10:22:12.656153Z",
     "shell.execute_reply": "2024-12-07T10:22:12.655064Z",
     "shell.execute_reply.started": "2024-12-07T10:20:43.325553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (3960, 160) || Test Shape : (20, 159)\n",
      "CPU times: user 6.61 s, sys: 710 ms, total: 7.32 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(raw_train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(raw_test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputed_data = imputer.fit_transform(train[numeric_cols])\n",
    "train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "        \n",
    "train = train_imputed\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii', 'BMI_Age','Internet_Hours_Age','BMI_Internet_Hours',\n",
    "                'BFP_BMI', 'FFMI_BFP', 'FMI_BFP', 'LST_TBW', 'BFP_BMR', 'BFP_DEE', 'BMR_Weight', 'DEE_Weight',\n",
    "                'SMM_Height', 'Muscle_to_Fat', 'Hydration_Status', 'ICW_TBW']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "featuresCols.remove('sii')\n",
    "test = test[featuresCols]\n",
    "\n",
    "print(f'Train Shape : {train.shape} || Test Shape : {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T10:19:30.410946Z",
     "iopub.status.idle": "2024-12-07T10:19:30.411499Z",
     "shell.execute_reply": "2024-12-07T10:19:30.411260Z",
     "shell.execute_reply.started": "2024-12-07T10:19:30.411224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 μs, sys: 0 ns, total: 118 μs\n",
      "Wall time: 122 μs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Diastolic_BP</th>\n",
       "      <th>Physical-HeartRate</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>Fitness_Endurance-Max_Stage</th>\n",
       "      <th>Fitness_Endurance-Time_Mins</th>\n",
       "      <th>Fitness_Endurance-Time_Sec</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_CU_Zone</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSND_Zone</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>FGC-FGC_GSD_Zone</th>\n",
       "      <th>FGC-FGC_PU</th>\n",
       "      <th>FGC-FGC_PU_Zone</th>\n",
       "      <th>FGC-FGC_SRL</th>\n",
       "      <th>FGC-FGC_SRL_Zone</th>\n",
       "      <th>FGC-FGC_SRR</th>\n",
       "      <th>FGC-FGC_SRR_Zone</th>\n",
       "      <th>FGC-FGC_TL</th>\n",
       "      <th>FGC-FGC_TL_Zone</th>\n",
       "      <th>BIA-BIA_Activity_Level_num</th>\n",
       "      <th>BIA-BIA_BMC</th>\n",
       "      <th>BIA-BIA_BMI</th>\n",
       "      <th>BIA-BIA_BMR</th>\n",
       "      <th>BIA-BIA_DEE</th>\n",
       "      <th>BIA-BIA_ECW</th>\n",
       "      <th>BIA-BIA_FFM</th>\n",
       "      <th>BIA-BIA_FFMI</th>\n",
       "      <th>BIA-BIA_FMI</th>\n",
       "      <th>BIA-BIA_Fat</th>\n",
       "      <th>BIA-BIA_Frame_num</th>\n",
       "      <th>BIA-BIA_ICW</th>\n",
       "      <th>BIA-BIA_LDM</th>\n",
       "      <th>BIA-BIA_LST</th>\n",
       "      <th>BIA-BIA_SMM</th>\n",
       "      <th>BIA-BIA_TBW</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "      <th>BMI_Age</th>\n",
       "      <th>Internet_Hours_Age</th>\n",
       "      <th>BMI_Internet_Hours</th>\n",
       "      <th>BFP_BMI</th>\n",
       "      <th>FFMI_BFP</th>\n",
       "      <th>FMI_BFP</th>\n",
       "      <th>LST_TBW</th>\n",
       "      <th>BFP_BMR</th>\n",
       "      <th>BFP_DEE</th>\n",
       "      <th>BMR_Weight</th>\n",
       "      <th>DEE_Weight</th>\n",
       "      <th>SMM_Height</th>\n",
       "      <th>Muscle_to_Fat</th>\n",
       "      <th>Hydration_Status</th>\n",
       "      <th>ICW_TBW</th>\n",
       "      <th>Stat_0</th>\n",
       "      <th>Stat_1</th>\n",
       "      <th>Stat_2</th>\n",
       "      <th>Stat_3</th>\n",
       "      <th>Stat_4</th>\n",
       "      <th>Stat_5</th>\n",
       "      <th>Stat_6</th>\n",
       "      <th>Stat_7</th>\n",
       "      <th>Stat_8</th>\n",
       "      <th>Stat_9</th>\n",
       "      <th>Stat_10</th>\n",
       "      <th>Stat_11</th>\n",
       "      <th>Stat_12</th>\n",
       "      <th>Stat_13</th>\n",
       "      <th>Stat_14</th>\n",
       "      <th>Stat_15</th>\n",
       "      <th>Stat_16</th>\n",
       "      <th>Stat_17</th>\n",
       "      <th>Stat_18</th>\n",
       "      <th>Stat_19</th>\n",
       "      <th>Stat_20</th>\n",
       "      <th>Stat_21</th>\n",
       "      <th>Stat_22</th>\n",
       "      <th>Stat_23</th>\n",
       "      <th>Stat_24</th>\n",
       "      <th>Stat_25</th>\n",
       "      <th>Stat_26</th>\n",
       "      <th>Stat_27</th>\n",
       "      <th>Stat_28</th>\n",
       "      <th>Stat_29</th>\n",
       "      <th>Stat_30</th>\n",
       "      <th>Stat_31</th>\n",
       "      <th>Stat_32</th>\n",
       "      <th>Stat_33</th>\n",
       "      <th>Stat_34</th>\n",
       "      <th>Stat_35</th>\n",
       "      <th>Stat_36</th>\n",
       "      <th>Stat_37</th>\n",
       "      <th>Stat_38</th>\n",
       "      <th>Stat_39</th>\n",
       "      <th>Stat_40</th>\n",
       "      <th>Stat_41</th>\n",
       "      <th>Stat_42</th>\n",
       "      <th>Stat_43</th>\n",
       "      <th>Stat_44</th>\n",
       "      <th>Stat_45</th>\n",
       "      <th>Stat_46</th>\n",
       "      <th>Stat_47</th>\n",
       "      <th>Stat_48</th>\n",
       "      <th>Stat_49</th>\n",
       "      <th>Stat_50</th>\n",
       "      <th>Stat_51</th>\n",
       "      <th>Stat_52</th>\n",
       "      <th>Stat_53</th>\n",
       "      <th>Stat_54</th>\n",
       "      <th>Stat_55</th>\n",
       "      <th>Stat_56</th>\n",
       "      <th>Stat_57</th>\n",
       "      <th>Stat_58</th>\n",
       "      <th>Stat_59</th>\n",
       "      <th>Stat_60</th>\n",
       "      <th>Stat_61</th>\n",
       "      <th>Stat_62</th>\n",
       "      <th>Stat_63</th>\n",
       "      <th>Stat_64</th>\n",
       "      <th>Stat_65</th>\n",
       "      <th>Stat_66</th>\n",
       "      <th>Stat_67</th>\n",
       "      <th>Stat_68</th>\n",
       "      <th>Stat_69</th>\n",
       "      <th>Stat_70</th>\n",
       "      <th>Stat_71</th>\n",
       "      <th>Stat_72</th>\n",
       "      <th>Stat_73</th>\n",
       "      <th>Stat_74</th>\n",
       "      <th>Stat_75</th>\n",
       "      <th>Stat_76</th>\n",
       "      <th>Stat_77</th>\n",
       "      <th>Stat_78</th>\n",
       "      <th>Stat_79</th>\n",
       "      <th>Stat_80</th>\n",
       "      <th>Stat_81</th>\n",
       "      <th>Stat_82</th>\n",
       "      <th>Stat_83</th>\n",
       "      <th>Stat_84</th>\n",
       "      <th>Stat_85</th>\n",
       "      <th>Stat_86</th>\n",
       "      <th>Stat_87</th>\n",
       "      <th>Stat_88</th>\n",
       "      <th>Stat_89</th>\n",
       "      <th>Stat_90</th>\n",
       "      <th>Stat_91</th>\n",
       "      <th>Stat_92</th>\n",
       "      <th>Stat_93</th>\n",
       "      <th>Stat_94</th>\n",
       "      <th>Stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.80</td>\n",
       "      <td>23.0</td>\n",
       "      <td>61.2</td>\n",
       "      <td>86.4</td>\n",
       "      <td>110.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1.8</td>\n",
       "      <td>16.18</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.668550</td>\n",
       "      <td>16.87920</td>\n",
       "      <td>932.4980</td>\n",
       "      <td>1492.000</td>\n",
       "      <td>8.255980</td>\n",
       "      <td>41.58620</td>\n",
       "      <td>13.81770</td>\n",
       "      <td>3.061430</td>\n",
       "      <td>9.213770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.43490</td>\n",
       "      <td>8.895360</td>\n",
       "      <td>38.91770</td>\n",
       "      <td>19.54130</td>\n",
       "      <td>32.69090</td>\n",
       "      <td>1.9120</td>\n",
       "      <td>2.2220</td>\n",
       "      <td>48.4</td>\n",
       "      <td>62.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>84.386578</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.631947</td>\n",
       "      <td>0.545865</td>\n",
       "      <td>1.499679</td>\n",
       "      <td>0.332267</td>\n",
       "      <td>1.190475</td>\n",
       "      <td>8591.822097</td>\n",
       "      <td>13746.944840</td>\n",
       "      <td>18.356260</td>\n",
       "      <td>29.370079</td>\n",
       "      <td>0.424811</td>\n",
       "      <td>6.383063</td>\n",
       "      <td>0.643522</td>\n",
       "      <td>0.747453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>24.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.04</td>\n",
       "      <td>1.6</td>\n",
       "      <td>15.50</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.579490</td>\n",
       "      <td>14.03710</td>\n",
       "      <td>936.6560</td>\n",
       "      <td>1498.650</td>\n",
       "      <td>6.019930</td>\n",
       "      <td>42.02910</td>\n",
       "      <td>12.82540</td>\n",
       "      <td>1.211720</td>\n",
       "      <td>3.970850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.03520</td>\n",
       "      <td>14.974000</td>\n",
       "      <td>39.44970</td>\n",
       "      <td>15.41070</td>\n",
       "      <td>27.05520</td>\n",
       "      <td>2.6260</td>\n",
       "      <td>2.3400</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.320313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282883</td>\n",
       "      <td>3.229888</td>\n",
       "      <td>0.305154</td>\n",
       "      <td>1.458119</td>\n",
       "      <td>3719.320478</td>\n",
       "      <td>5950.914352</td>\n",
       "      <td>20.362087</td>\n",
       "      <td>32.579348</td>\n",
       "      <td>0.321056</td>\n",
       "      <td>12.718037</td>\n",
       "      <td>0.588157</td>\n",
       "      <td>0.777492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.60</td>\n",
       "      <td>24.8</td>\n",
       "      <td>65.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.428146</td>\n",
       "      <td>19.09980</td>\n",
       "      <td>1105.3782</td>\n",
       "      <td>1887.522</td>\n",
       "      <td>17.112254</td>\n",
       "      <td>60.00024</td>\n",
       "      <td>14.86322</td>\n",
       "      <td>4.236552</td>\n",
       "      <td>17.519748</td>\n",
       "      <td>2.6</td>\n",
       "      <td>28.95074</td>\n",
       "      <td>13.937256</td>\n",
       "      <td>56.57208</td>\n",
       "      <td>28.11530</td>\n",
       "      <td>46.06298</td>\n",
       "      <td>2.0938</td>\n",
       "      <td>2.1700</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.486961</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.297392</td>\n",
       "      <td>0.917274</td>\n",
       "      <td>0.848370</td>\n",
       "      <td>0.241816</td>\n",
       "      <td>1.228146</td>\n",
       "      <td>19365.947509</td>\n",
       "      <td>33068.909784</td>\n",
       "      <td>14.621405</td>\n",
       "      <td>24.967222</td>\n",
       "      <td>0.497616</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>0.609299</td>\n",
       "      <td>0.628503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.60</td>\n",
       "      <td>25.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.50</td>\n",
       "      <td>1.6</td>\n",
       "      <td>16.92</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.841910</td>\n",
       "      <td>18.29430</td>\n",
       "      <td>1131.4300</td>\n",
       "      <td>1923.440</td>\n",
       "      <td>15.592500</td>\n",
       "      <td>62.77570</td>\n",
       "      <td>14.07400</td>\n",
       "      <td>4.220330</td>\n",
       "      <td>18.824300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.40410</td>\n",
       "      <td>16.779000</td>\n",
       "      <td>58.93380</td>\n",
       "      <td>26.47980</td>\n",
       "      <td>45.99660</td>\n",
       "      <td>1.7980</td>\n",
       "      <td>2.4510</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>164.631122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028971</td>\n",
       "      <td>0.747651</td>\n",
       "      <td>0.224196</td>\n",
       "      <td>1.281264</td>\n",
       "      <td>21298.377749</td>\n",
       "      <td>36207.411592</td>\n",
       "      <td>13.865564</td>\n",
       "      <td>23.571569</td>\n",
       "      <td>0.472854</td>\n",
       "      <td>6.274343</td>\n",
       "      <td>0.563684</td>\n",
       "      <td>0.661008</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>-0.316384</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>-0.16789</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>-10.580416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.29631</td>\n",
       "      <td>4053.579102</td>\n",
       "      <td>5.046215e+13</td>\n",
       "      <td>4.470182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.201683</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>0.502702</td>\n",
       "      <td>0.58571</td>\n",
       "      <td>0.106351</td>\n",
       "      <td>42.94717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.168976</td>\n",
       "      <td>112.404045</td>\n",
       "      <td>1.942842e+13</td>\n",
       "      <td>1.931421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.244915</td>\n",
       "      <td>-1.746094</td>\n",
       "      <td>-2.905339</td>\n",
       "      <td>-1.048372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-89.833092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3824.0</td>\n",
       "      <td>5.500000e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.68418</td>\n",
       "      <td>-0.309863</td>\n",
       "      <td>-0.649974</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>-41.541862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.392969</td>\n",
       "      <td>4028.666748</td>\n",
       "      <td>3.689000e+13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-0.366849</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-0.245378</td>\n",
       "      <td>0.023637</td>\n",
       "      <td>-15.086617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.926828</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>5.347750e+13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>0.400677</td>\n",
       "      <td>0.204727</td>\n",
       "      <td>0.04142</td>\n",
       "      <td>12.220764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>6.640875e+13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.507865</td>\n",
       "      <td>1.666354</td>\n",
       "      <td>1.546979</td>\n",
       "      <td>4.004276</td>\n",
       "      <td>89.751656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2633.25</td>\n",
       "      <td>4188.5</td>\n",
       "      <td>8.611000e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>25.826448</td>\n",
       "      <td>62.7</td>\n",
       "      <td>138.92</td>\n",
       "      <td>33.6</td>\n",
       "      <td>71.6</td>\n",
       "      <td>74.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>28.48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.508754</td>\n",
       "      <td>26.06438</td>\n",
       "      <td>1413.5700</td>\n",
       "      <td>2200.970</td>\n",
       "      <td>30.476360</td>\n",
       "      <td>92.82690</td>\n",
       "      <td>16.12118</td>\n",
       "      <td>9.943228</td>\n",
       "      <td>56.733100</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36.12276</td>\n",
       "      <td>26.227860</td>\n",
       "      <td>88.31828</td>\n",
       "      <td>48.99876</td>\n",
       "      <td>66.59910</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>2.1522</td>\n",
       "      <td>41.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>464.876065</td>\n",
       "      <td>46.8</td>\n",
       "      <td>67.148765</td>\n",
       "      <td>2.176653</td>\n",
       "      <td>0.284158</td>\n",
       "      <td>0.175263</td>\n",
       "      <td>1.326118</td>\n",
       "      <td>80196.208167</td>\n",
       "      <td>124867.851107</td>\n",
       "      <td>10.175425</td>\n",
       "      <td>15.843435</td>\n",
       "      <td>0.781479</td>\n",
       "      <td>4.927852</td>\n",
       "      <td>0.479406</td>\n",
       "      <td>0.542391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  Physical-BMI  Physical-Height  Physical-Weight  Physical-Waist_Circumference  Physical-Diastolic_BP  Physical-HeartRate  Physical-Systolic_BP  Fitness_Endurance-Max_Stage  Fitness_Endurance-Time_Mins  Fitness_Endurance-Time_Sec  FGC-FGC_CU  FGC-FGC_CU_Zone  FGC-FGC_GSND  FGC-FGC_GSND_Zone  FGC-FGC_GSD  FGC-FGC_GSD_Zone  FGC-FGC_PU  FGC-FGC_PU_Zone  FGC-FGC_SRL  FGC-FGC_SRL_Zone  FGC-FGC_SRR  FGC-FGC_SRR_Zone  FGC-FGC_TL  FGC-FGC_TL_Zone  BIA-BIA_Activity_Level_num  BIA-BIA_BMC  BIA-BIA_BMI  BIA-BIA_BMR  BIA-BIA_DEE  BIA-BIA_ECW  BIA-BIA_FFM  BIA-BIA_FFMI  BIA-BIA_FMI  BIA-BIA_Fat  BIA-BIA_Frame_num  BIA-BIA_ICW  BIA-BIA_LDM  BIA-BIA_LST  BIA-BIA_SMM  BIA-BIA_TBW  PAQ_A-PAQ_A_Total  PAQ_C-PAQ_C_Total  SDS-SDS_Total_Raw  SDS-SDS_Total_T  PreInt_EduHx-computerinternet_hoursday  sii     BMI_Age  Internet_Hours_Age  BMI_Internet_Hours   BFP_BMI  FFMI_BFP   FMI_BFP   LST_TBW       BFP_BMR        BFP_DEE  BMR_Weight  DEE_Weight  SMM_Height  Muscle_to_Fat  Hydration_Status   ICW_TBW   Stat_0   Stat_1   Stat_2   Stat_3   Stat_4   Stat_5   Stat_6   Stat_7   Stat_8   Stat_9  Stat_10  Stat_11   Stat_12   Stat_13  Stat_14   Stat_15    Stat_16  Stat_17   Stat_18      Stat_19       Stat_20   Stat_21  Stat_22    Stat_23   Stat_24   Stat_25  Stat_26   Stat_27   Stat_28  Stat_29     Stat_30     Stat_31       Stat_32   Stat_33  Stat_34    Stat_35   Stat_36   Stat_37   Stat_38  Stat_39    Stat_40  Stat_41  Stat_42  Stat_43       Stat_44  Stat_45  Stat_46  Stat_47  Stat_48   Stat_49   Stat_50   Stat_51    Stat_52  Stat_53   Stat_54      Stat_55       Stat_56  Stat_57  Stat_58  Stat_59   Stat_60   Stat_61   Stat_62   Stat_63    Stat_64  Stat_65   Stat_66  Stat_67       Stat_68  Stat_69  Stat_70  Stat_71   Stat_72   Stat_73   Stat_74  Stat_75    Stat_76  Stat_77  Stat_78  Stat_79       Stat_80  Stat_81  Stat_82  Stat_83   Stat_84   Stat_85   Stat_86   Stat_87    Stat_88  Stat_89  Stat_90  Stat_91       Stat_92  Stat_93  Stat_94  Stat_95\n",
       "0              5.0              0.0             51.0     16.877316             46.0            50.80                          23.0                   61.2                86.4                 110.6                          4.0                          5.8                        27.0         0.0              0.0         17.56                1.8        16.18               1.4         0.0              0.0          7.0               0.0          6.0               0.0         6.0              1.0                         2.0     2.668550     16.87920     932.4980     1492.000     8.255980     41.58620      13.81770     3.061430     9.213770                1.0     24.43490     8.895360     38.91770     19.54130     32.69090             1.9120             2.2220               48.4             62.2                                     3.0    2   84.386578                15.0           50.631947  0.545865  1.499679  0.332267  1.190475   8591.822097   13746.944840   18.356260   29.370079    0.424811       6.383063          0.643522  0.747453      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN\n",
       "1              9.0              0.0             70.0     14.035590             48.0            46.00                          22.0                   75.0                70.0                 122.0                          4.6                          6.6                        24.2         3.0              0.0         16.04                1.6        15.50               1.6         5.0              0.0         11.0               1.0         11.0               1.0         3.0              0.0                         2.0     2.579490     14.03710     936.6560     1498.650     6.019930     42.02910      12.82540     1.211720     3.970850                1.0     21.03520    14.974000     39.44970     15.41070     27.05520             2.6260             2.3400               46.0             64.0                                     0.0    0  126.320313                 0.0            0.000000  0.282883  3.229888  0.305154  1.458119   3719.320478    5950.914352   20.362087   32.579348    0.321056      12.718037          0.588157  0.777492      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN\n",
       "2             10.0              1.0             71.0     16.648696             56.5            75.60                          24.8                   65.0                94.0                 117.0                          5.0                          7.0                        33.0        20.0              1.0         10.20                1.0        14.70               2.0         7.0              1.0         10.0               1.0         10.0               1.0         5.0              0.0                         2.6     3.428146     19.09980    1105.3782     1887.522    17.112254     60.00024      14.86322     4.236552    17.519748                2.6     28.95074    13.937256     56.57208     28.11530     46.06298             2.0938             2.1700               38.0             54.0                                     2.0    0  166.486961                20.0           33.297392  0.917274  0.848370  0.241816  1.228146  19365.947509   33068.909784   14.621405   24.967222    0.497616       6.636364          0.609299  0.628503      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN\n",
       "3              9.0              0.0             71.0     18.292347             56.0            81.60                          25.4                   60.0                97.0                 117.0                          6.0                          9.0                        37.0        18.0              1.0         14.50                1.6        16.92               2.2         5.0              0.0          7.0               0.0          7.0               0.0         7.0              1.0                         3.0     3.841910     18.29430    1131.4300     1923.440    15.592500     62.77570      14.07400     4.220330    18.824300                2.0     30.40410    16.779000     58.93380     26.47980     45.99660             1.7980             2.4510               31.0             45.0                                     0.0    1  164.631122                 0.0            0.000000  1.028971  0.747651  0.224196  1.281264  21298.377749   36207.411592   13.865564   23.571569    0.472854       6.274343          0.563684  0.661008  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0 -0.316384  0.016009 -0.16789  0.047388 -10.580416      0.0  42.29631  4053.579102  5.046215e+13  4.470182      3.0  53.201683  0.453665  0.502702  0.58571  0.106351  42.94717      0.0  208.168976  112.404045  1.942842e+13  1.931421      0.0  14.244915 -1.746094 -2.905339 -1.048372      0.0 -89.833092      0.0      0.0   3824.0  5.500000e+10      1.0      3.0     41.0 -0.68418 -0.309863 -0.649974  0.006432 -41.541862      0.0  2.392969  4028.666748  3.689000e+13      3.0      3.0     42.0 -0.366849  0.024974 -0.245378  0.023637 -15.086617      0.0  6.926828   4070.0  5.347750e+13      5.0      3.0     50.0 -0.010677  0.400677  0.204727  0.04142  12.220764      0.0     15.0   4147.0  6.640875e+13      6.0      3.0     53.0  1.507865  1.666354  1.546979  4.004276  89.751656      0.0  2633.25   4188.5  8.611000e+13      7.0      3.0     85.0\n",
       "4             18.0              1.0             74.0     25.826448             62.7           138.92                          33.6                   71.6                74.4                 121.0                          4.6                          5.4                        23.6        12.8              0.2         28.48                2.0        28.80               2.0         1.4              0.0         10.1               0.6          9.5               0.6        10.7              0.8                         2.6     4.508754     26.06438    1413.5700     2200.970    30.476360     92.82690      16.12118     9.943228    56.733100                2.4     36.12276    26.227860     88.31828     48.99876     66.59910             1.0400             2.1522               41.0             59.2                                     2.6    1  464.876065                46.8           67.148765  2.176653  0.284158  0.175263  1.326118  80196.208167  124867.851107   10.175425   15.843435    0.781479       4.927852          0.479406  0.542391      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T10:19:30.412425Z",
     "iopub.status.idle": "2024-12-07T10:19:30.412926Z",
     "shell.execute_reply": "2024-12-07T10:19:30.412685Z",
     "shell.execute_reply.started": "2024-12-07T10:19:30.412660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 135 μs, sys: 0 ns, total: 135 μs\n",
      "Wall time: 138 μs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Diastolic_BP</th>\n",
       "      <th>Physical-HeartRate</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>Fitness_Endurance-Max_Stage</th>\n",
       "      <th>Fitness_Endurance-Time_Mins</th>\n",
       "      <th>Fitness_Endurance-Time_Sec</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_CU_Zone</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSND_Zone</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>FGC-FGC_GSD_Zone</th>\n",
       "      <th>FGC-FGC_PU</th>\n",
       "      <th>FGC-FGC_PU_Zone</th>\n",
       "      <th>FGC-FGC_SRL</th>\n",
       "      <th>FGC-FGC_SRL_Zone</th>\n",
       "      <th>FGC-FGC_SRR</th>\n",
       "      <th>FGC-FGC_SRR_Zone</th>\n",
       "      <th>FGC-FGC_TL</th>\n",
       "      <th>FGC-FGC_TL_Zone</th>\n",
       "      <th>BIA-BIA_Activity_Level_num</th>\n",
       "      <th>BIA-BIA_BMC</th>\n",
       "      <th>BIA-BIA_BMI</th>\n",
       "      <th>BIA-BIA_BMR</th>\n",
       "      <th>BIA-BIA_DEE</th>\n",
       "      <th>BIA-BIA_ECW</th>\n",
       "      <th>BIA-BIA_FFM</th>\n",
       "      <th>BIA-BIA_FFMI</th>\n",
       "      <th>BIA-BIA_FMI</th>\n",
       "      <th>BIA-BIA_Fat</th>\n",
       "      <th>BIA-BIA_Frame_num</th>\n",
       "      <th>BIA-BIA_ICW</th>\n",
       "      <th>BIA-BIA_LDM</th>\n",
       "      <th>BIA-BIA_LST</th>\n",
       "      <th>BIA-BIA_SMM</th>\n",
       "      <th>BIA-BIA_TBW</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>BMI_Age</th>\n",
       "      <th>Internet_Hours_Age</th>\n",
       "      <th>BMI_Internet_Hours</th>\n",
       "      <th>BFP_BMI</th>\n",
       "      <th>FFMI_BFP</th>\n",
       "      <th>FMI_BFP</th>\n",
       "      <th>LST_TBW</th>\n",
       "      <th>BFP_BMR</th>\n",
       "      <th>BFP_DEE</th>\n",
       "      <th>BMR_Weight</th>\n",
       "      <th>DEE_Weight</th>\n",
       "      <th>SMM_Height</th>\n",
       "      <th>Muscle_to_Fat</th>\n",
       "      <th>Hydration_Status</th>\n",
       "      <th>ICW_TBW</th>\n",
       "      <th>Stat_0</th>\n",
       "      <th>Stat_1</th>\n",
       "      <th>Stat_2</th>\n",
       "      <th>Stat_3</th>\n",
       "      <th>Stat_4</th>\n",
       "      <th>Stat_5</th>\n",
       "      <th>Stat_6</th>\n",
       "      <th>Stat_7</th>\n",
       "      <th>Stat_8</th>\n",
       "      <th>Stat_9</th>\n",
       "      <th>Stat_10</th>\n",
       "      <th>Stat_11</th>\n",
       "      <th>Stat_12</th>\n",
       "      <th>Stat_13</th>\n",
       "      <th>Stat_14</th>\n",
       "      <th>Stat_15</th>\n",
       "      <th>Stat_16</th>\n",
       "      <th>Stat_17</th>\n",
       "      <th>Stat_18</th>\n",
       "      <th>Stat_19</th>\n",
       "      <th>Stat_20</th>\n",
       "      <th>Stat_21</th>\n",
       "      <th>Stat_22</th>\n",
       "      <th>Stat_23</th>\n",
       "      <th>Stat_24</th>\n",
       "      <th>Stat_25</th>\n",
       "      <th>Stat_26</th>\n",
       "      <th>Stat_27</th>\n",
       "      <th>Stat_28</th>\n",
       "      <th>Stat_29</th>\n",
       "      <th>Stat_30</th>\n",
       "      <th>Stat_31</th>\n",
       "      <th>Stat_32</th>\n",
       "      <th>Stat_33</th>\n",
       "      <th>Stat_34</th>\n",
       "      <th>Stat_35</th>\n",
       "      <th>Stat_36</th>\n",
       "      <th>Stat_37</th>\n",
       "      <th>Stat_38</th>\n",
       "      <th>Stat_39</th>\n",
       "      <th>Stat_40</th>\n",
       "      <th>Stat_41</th>\n",
       "      <th>Stat_42</th>\n",
       "      <th>Stat_43</th>\n",
       "      <th>Stat_44</th>\n",
       "      <th>Stat_45</th>\n",
       "      <th>Stat_46</th>\n",
       "      <th>Stat_47</th>\n",
       "      <th>Stat_48</th>\n",
       "      <th>Stat_49</th>\n",
       "      <th>Stat_50</th>\n",
       "      <th>Stat_51</th>\n",
       "      <th>Stat_52</th>\n",
       "      <th>Stat_53</th>\n",
       "      <th>Stat_54</th>\n",
       "      <th>Stat_55</th>\n",
       "      <th>Stat_56</th>\n",
       "      <th>Stat_57</th>\n",
       "      <th>Stat_58</th>\n",
       "      <th>Stat_59</th>\n",
       "      <th>Stat_60</th>\n",
       "      <th>Stat_61</th>\n",
       "      <th>Stat_62</th>\n",
       "      <th>Stat_63</th>\n",
       "      <th>Stat_64</th>\n",
       "      <th>Stat_65</th>\n",
       "      <th>Stat_66</th>\n",
       "      <th>Stat_67</th>\n",
       "      <th>Stat_68</th>\n",
       "      <th>Stat_69</th>\n",
       "      <th>Stat_70</th>\n",
       "      <th>Stat_71</th>\n",
       "      <th>Stat_72</th>\n",
       "      <th>Stat_73</th>\n",
       "      <th>Stat_74</th>\n",
       "      <th>Stat_75</th>\n",
       "      <th>Stat_76</th>\n",
       "      <th>Stat_77</th>\n",
       "      <th>Stat_78</th>\n",
       "      <th>Stat_79</th>\n",
       "      <th>Stat_80</th>\n",
       "      <th>Stat_81</th>\n",
       "      <th>Stat_82</th>\n",
       "      <th>Stat_83</th>\n",
       "      <th>Stat_84</th>\n",
       "      <th>Stat_85</th>\n",
       "      <th>Stat_86</th>\n",
       "      <th>Stat_87</th>\n",
       "      <th>Stat_88</th>\n",
       "      <th>Stat_89</th>\n",
       "      <th>Stat_90</th>\n",
       "      <th>Stat_91</th>\n",
       "      <th>Stat_92</th>\n",
       "      <th>Stat_93</th>\n",
       "      <th>Stat_94</th>\n",
       "      <th>Stat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.66855</td>\n",
       "      <td>16.8792</td>\n",
       "      <td>932.498</td>\n",
       "      <td>1492.00</td>\n",
       "      <td>8.25598</td>\n",
       "      <td>41.5862</td>\n",
       "      <td>13.8177</td>\n",
       "      <td>3.06143</td>\n",
       "      <td>9.21377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.4349</td>\n",
       "      <td>8.89536</td>\n",
       "      <td>38.9177</td>\n",
       "      <td>19.5413</td>\n",
       "      <td>32.6909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.386578</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.631947</td>\n",
       "      <td>0.545865</td>\n",
       "      <td>1.499679</td>\n",
       "      <td>0.332267</td>\n",
       "      <td>1.190475</td>\n",
       "      <td>8591.822097</td>\n",
       "      <td>13746.944840</td>\n",
       "      <td>18.356260</td>\n",
       "      <td>29.370079</td>\n",
       "      <td>0.424811</td>\n",
       "      <td>6.383063</td>\n",
       "      <td>0.643522</td>\n",
       "      <td>0.747453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.57949</td>\n",
       "      <td>14.0371</td>\n",
       "      <td>936.656</td>\n",
       "      <td>1498.65</td>\n",
       "      <td>6.01993</td>\n",
       "      <td>42.0291</td>\n",
       "      <td>12.8254</td>\n",
       "      <td>1.21172</td>\n",
       "      <td>3.97085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0352</td>\n",
       "      <td>14.97400</td>\n",
       "      <td>39.4497</td>\n",
       "      <td>15.4107</td>\n",
       "      <td>27.0552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.340</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.320313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282883</td>\n",
       "      <td>3.229888</td>\n",
       "      <td>0.305154</td>\n",
       "      <td>1.458119</td>\n",
       "      <td>3719.320478</td>\n",
       "      <td>5950.914352</td>\n",
       "      <td>20.362087</td>\n",
       "      <td>32.579348</td>\n",
       "      <td>0.321056</td>\n",
       "      <td>12.718037</td>\n",
       "      <td>0.588157</td>\n",
       "      <td>0.777492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.170</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>166.486961</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.297392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.84191</td>\n",
       "      <td>18.2943</td>\n",
       "      <td>1131.430</td>\n",
       "      <td>1923.44</td>\n",
       "      <td>15.59250</td>\n",
       "      <td>62.7757</td>\n",
       "      <td>14.0740</td>\n",
       "      <td>4.22033</td>\n",
       "      <td>18.82430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.4041</td>\n",
       "      <td>16.77900</td>\n",
       "      <td>58.9338</td>\n",
       "      <td>26.4798</td>\n",
       "      <td>45.9966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.451</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.631122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028971</td>\n",
       "      <td>0.747651</td>\n",
       "      <td>0.224196</td>\n",
       "      <td>1.281264</td>\n",
       "      <td>21298.377749</td>\n",
       "      <td>36207.411592</td>\n",
       "      <td>13.865564</td>\n",
       "      <td>23.571569</td>\n",
       "      <td>0.472854</td>\n",
       "      <td>6.274343</td>\n",
       "      <td>0.563684</td>\n",
       "      <td>0.661008</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>-0.316384</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>-0.16789</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>-10.580416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.29631</td>\n",
       "      <td>4053.579102</td>\n",
       "      <td>5.046215e+13</td>\n",
       "      <td>4.470182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.201683</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>0.502702</td>\n",
       "      <td>0.58571</td>\n",
       "      <td>0.106351</td>\n",
       "      <td>42.94717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.168976</td>\n",
       "      <td>112.404045</td>\n",
       "      <td>1.942842e+13</td>\n",
       "      <td>1.931421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.244915</td>\n",
       "      <td>-1.746094</td>\n",
       "      <td>-2.905339</td>\n",
       "      <td>-1.048372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-89.833092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3824.0</td>\n",
       "      <td>5.500000e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.68418</td>\n",
       "      <td>-0.309863</td>\n",
       "      <td>-0.649974</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>-41.541862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.392969</td>\n",
       "      <td>4028.666748</td>\n",
       "      <td>3.689000e+13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-0.366849</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-0.245378</td>\n",
       "      <td>0.023637</td>\n",
       "      <td>-15.086617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.926828</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>5.347750e+13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>0.400677</td>\n",
       "      <td>0.204727</td>\n",
       "      <td>0.04142</td>\n",
       "      <td>12.220764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>6.640875e+13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.507865</td>\n",
       "      <td>1.666354</td>\n",
       "      <td>1.546979</td>\n",
       "      <td>4.004276</td>\n",
       "      <td>89.751656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2633.25</td>\n",
       "      <td>4188.5</td>\n",
       "      <td>8.611000e+13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Basic_Demos-Age  Basic_Demos-Sex  CGAS-CGAS_Score  Physical-BMI  Physical-Height  Physical-Weight  Physical-Waist_Circumference  Physical-Diastolic_BP  Physical-HeartRate  Physical-Systolic_BP  Fitness_Endurance-Max_Stage  Fitness_Endurance-Time_Mins  Fitness_Endurance-Time_Sec  FGC-FGC_CU  FGC-FGC_CU_Zone  FGC-FGC_GSND  FGC-FGC_GSND_Zone  FGC-FGC_GSD  FGC-FGC_GSD_Zone  FGC-FGC_PU  FGC-FGC_PU_Zone  FGC-FGC_SRL  FGC-FGC_SRL_Zone  FGC-FGC_SRR  FGC-FGC_SRR_Zone  FGC-FGC_TL  FGC-FGC_TL_Zone  BIA-BIA_Activity_Level_num  BIA-BIA_BMC  BIA-BIA_BMI  BIA-BIA_BMR  BIA-BIA_DEE  BIA-BIA_ECW  BIA-BIA_FFM  BIA-BIA_FFMI  BIA-BIA_FMI  BIA-BIA_Fat  BIA-BIA_Frame_num  BIA-BIA_ICW  BIA-BIA_LDM  BIA-BIA_LST  BIA-BIA_SMM  BIA-BIA_TBW  PAQ_A-PAQ_A_Total  PAQ_C-PAQ_C_Total  SDS-SDS_Total_Raw  SDS-SDS_Total_T  PreInt_EduHx-computerinternet_hoursday     BMI_Age  Internet_Hours_Age  BMI_Internet_Hours   BFP_BMI  FFMI_BFP   FMI_BFP   LST_TBW       BFP_BMR       BFP_DEE  BMR_Weight  DEE_Weight  SMM_Height  Muscle_to_Fat  Hydration_Status   ICW_TBW   Stat_0   Stat_1   Stat_2   Stat_3   Stat_4   Stat_5   Stat_6   Stat_7   Stat_8   Stat_9  Stat_10  Stat_11   Stat_12   Stat_13  Stat_14   Stat_15    Stat_16  Stat_17   Stat_18      Stat_19       Stat_20   Stat_21  Stat_22    Stat_23   Stat_24   Stat_25  Stat_26   Stat_27   Stat_28  Stat_29     Stat_30     Stat_31       Stat_32   Stat_33  Stat_34    Stat_35   Stat_36   Stat_37   Stat_38  Stat_39    Stat_40  Stat_41  Stat_42  Stat_43       Stat_44  Stat_45  Stat_46  Stat_47  Stat_48   Stat_49   Stat_50   Stat_51    Stat_52  Stat_53   Stat_54      Stat_55       Stat_56  Stat_57  Stat_58  Stat_59   Stat_60   Stat_61   Stat_62   Stat_63    Stat_64  Stat_65   Stat_66  Stat_67       Stat_68  Stat_69  Stat_70  Stat_71   Stat_72   Stat_73   Stat_74  Stat_75    Stat_76  Stat_77  Stat_78  Stat_79       Stat_80  Stat_81  Stat_82  Stat_83   Stat_84   Stat_85   Stat_86   Stat_87    Stat_88  Stat_89  Stat_90  Stat_91       Stat_92  Stat_93  Stat_94  Stat_95\n",
       "0                5                0             51.0     16.877316             46.0             50.8                           NaN                    NaN                 NaN                   NaN                          NaN                          NaN                         NaN         0.0              0.0           NaN                NaN          NaN               NaN         0.0              0.0          7.0               0.0          6.0               0.0         6.0              1.0                         2.0      2.66855      16.8792      932.498      1492.00      8.25598      41.5862       13.8177      3.06143      9.21377                1.0      24.4349      8.89536      38.9177      19.5413      32.6909                NaN                NaN                NaN              NaN                                     3.0   84.386578                15.0           50.631947  0.545865  1.499679  0.332267  1.190475   8591.822097  13746.944840   18.356260   29.370079    0.424811       6.383063          0.643522  0.747453      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN\n",
       "1                9                0              NaN     14.035590             48.0             46.0                          22.0                   75.0                70.0                 122.0                          NaN                          NaN                         NaN         3.0              0.0           NaN                NaN          NaN               NaN         5.0              0.0         11.0               1.0         11.0               1.0         3.0              0.0                         2.0      2.57949      14.0371      936.656      1498.65      6.01993      42.0291       12.8254      1.21172      3.97085                1.0      21.0352     14.97400      39.4497      15.4107      27.0552                NaN              2.340               46.0             64.0                                     0.0  126.320313                 0.0            0.000000  0.282883  3.229888  0.305154  1.458119   3719.320478   5950.914352   20.362087   32.579348    0.321056      12.718037          0.588157  0.777492      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN\n",
       "2               10                1             71.0     16.648696             56.5             75.6                           NaN                   65.0                94.0                 117.0                          5.0                          7.0                        33.0        20.0              1.0          10.2                1.0         14.7               2.0         7.0              1.0         10.0               1.0         10.0               1.0         5.0              0.0                         NaN          NaN          NaN          NaN          NaN          NaN          NaN           NaN          NaN          NaN                NaN          NaN          NaN          NaN          NaN          NaN                NaN              2.170               38.0             54.0                                     2.0  166.486961                20.0           33.297392       NaN       NaN       NaN       NaN           NaN           NaN         NaN         NaN         NaN            NaN               NaN       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN\n",
       "3                9                0             71.0     18.292347             56.0             81.6                           NaN                   60.0                97.0                 117.0                          6.0                          9.0                        37.0        18.0              1.0           NaN                NaN          NaN               NaN         5.0              0.0          7.0               0.0          7.0               0.0         7.0              1.0                         3.0      3.84191      18.2943     1131.430      1923.44     15.59250      62.7757       14.0740      4.22033     18.82430                2.0      30.4041     16.77900      58.9338      26.4798      45.9966                NaN              2.451               31.0             45.0                                     0.0  164.631122                 0.0            0.000000  1.028971  0.747651  0.224196  1.281264  21298.377749  36207.411592   13.865564   23.571569    0.472854       6.274343          0.563684  0.661008  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0  43330.0 -0.316384  0.016009 -0.16789  0.047388 -10.580416      0.0  42.29631  4053.579102  5.046215e+13  4.470182      3.0  53.201683  0.453665  0.502702  0.58571  0.106351  42.94717      0.0  208.168976  112.404045  1.942842e+13  1.931421      0.0  14.244915 -1.746094 -2.905339 -1.048372      0.0 -89.833092      0.0      0.0   3824.0  5.500000e+10      1.0      3.0     41.0 -0.68418 -0.309863 -0.649974  0.006432 -41.541862      0.0  2.392969  4028.666748  3.689000e+13      3.0      3.0     42.0 -0.366849  0.024974 -0.245378  0.023637 -15.086617      0.0  6.926828   4070.0  5.347750e+13      5.0      3.0     50.0 -0.010677  0.400677  0.204727  0.04142  12.220764      0.0     15.0   4147.0  6.640875e+13      6.0      3.0     53.0  1.507865  1.666354  1.546979  4.004276  89.751656      0.0  2633.25   4188.5  8.611000e+13      7.0      3.0     85.0\n",
       "4               18                1              NaN           NaN              NaN              NaN                           NaN                    NaN                 NaN                   NaN                          NaN                          NaN                         NaN         NaN              NaN           NaN                NaN          NaN               NaN         NaN              NaN          NaN               NaN          NaN               NaN         NaN              NaN                         NaN          NaN          NaN          NaN          NaN          NaN          NaN           NaN          NaN          NaN                NaN          NaN          NaN          NaN          NaN          NaN               1.04                NaN                NaN              NaN                                     NaN         NaN                 NaN                 NaN       NaN       NaN       NaN       NaN           NaN           NaN         NaN         NaN         NaN            NaN               NaN       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN       NaN       NaN      NaN       NaN        NaN      NaN       NaN          NaN           NaN       NaN      NaN        NaN       NaN       NaN      NaN       NaN       NaN      NaN         NaN         NaN           NaN       NaN      NaN        NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN        NaN      NaN       NaN          NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN       NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN      NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN       NaN       NaN       NaN       NaN        NaN      NaN      NaN      NaN           NaN      NaN      NaN      NaN"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T10:19:30.415078Z",
     "iopub.status.idle": "2024-12-07T10:19:30.415519Z",
     "shell.execute_reply": "2024-12-07T10:19:30.415327Z",
     "shell.execute_reply.started": "2024-12-07T10:19:30.415308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',  # Use 'reg:squarederror' for regression tasks\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 30, 1000),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 50),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 5),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-5, 10),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-5, 10),\n",
    "        'random_state': SEED,\n",
    "        'n_estimators': 1000  # Adjust the number of estimators or allow it to vary\n",
    "    }\n",
    "\n",
    "    # Prepare the data (this part is assumed to be defined outside this function)\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "    \n",
    "    n_splits = 5  # Define the number of splits for Stratified K-Folds (adjust as needed)\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float)\n",
    "    val_kappas = []  # To store validation QWK for each fold\n",
    "    \n",
    "    model_class = XGBRegressor(**params, missing=np.inf)\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)  # Clone model to ensure fresh instance each fold\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "\n",
    "        # Calculate validation QWK (quadratic weighted kappa) for the fold\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "        val_kappas.append(val_kappa)\n",
    "\n",
    "    # Calculate the average validation QWK across all folds (mean of the list)\n",
    "    mean_val_kappa = np.mean(val_kappas)\n",
    "\n",
    "    print(f\"Mean Validation QWK: {mean_val_kappa:.4f}\")\n",
    "    \n",
    "    # Return the negative validation QWK for optimization (since Optuna minimizes the objective)\n",
    "    return -mean_val_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna Study setup (only do one time)\n",
    "param = {}\n",
    "\n",
    "if param is None:\n",
    "    study = optuna.create_study(direction='minimize') \n",
    "    study.optimize(objective, n_trials=30)  # Number of trials to perform\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    param = {key: value for key, value in trial.params.items()}\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 478,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  # Increased from 6.59\n",
    "    'lambda_l2': 0.01,  # Increased from 2.68e-06\n",
    "    'device': 'cpu'\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1, \n",
    "    'reg_lambda': 5,\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'gpu_hist',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 μs, sys: 0 ns, total: 3 μs\n",
      "Wall time: 6.2 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    \n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead') # Nelder-Mead | # Powell\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(**param, n_estimators=200, missing=np.inf)\n",
    "light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:12<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.9867\n",
      "Mean Validation QWK ---> 0.5100\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.545\u001b[0m\n",
      "CPU times: user 2min 9s, sys: 180 ms, total: 2min 10s\n",
      "Wall time: 12.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', light),\n",
    "    ('xgboost', xgb)\n",
    "])\n",
    "\n",
    "Submission,model = TrainML(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    1\n",
       "1   000fd460    0\n",
       "2   00105258    1\n",
       "3   00115b9f    0\n",
       "4   0016bb22    1\n",
       "5   001f3379    1\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    1\n",
       "10  0087dd65    1\n",
       "11  00abe655    1\n",
       "12  00ae59c9    1\n",
       "13  00af6387    2\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    1\n",
       "17  00d9913d    1\n",
       "18  00e6167c    1\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sii\n",
      "1    15\n",
      "0     4\n",
      "2     1\n",
      "Name: count, dtype: int64\n",
      "CPU times: user 1.91 ms, sys: 0 ns, total: 1.91 ms\n",
      "Wall time: 1.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Submission.to_csv('submission.csv', index=False)\n",
    "print(Submission['sii'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:11<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.8475\n",
      "Mean Validation QWK ---> 0.4038\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.449\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    2\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    1\n",
       "5   001f3379    1\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    0\n",
       "10  0087dd65    0\n",
       "11  00abe655    0\n",
       "12  00ae59c9    2\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    2\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('./kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('./kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "        \n",
    "train_ts = load_time_series(\"./kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"./kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)   \n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping = create_mapping(col, train)\n",
    "    mappingTe = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping).astype(int)\n",
    "    test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 478,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  # Increased from 6.59\n",
    "    'lambda_l2': 0.01  # Increased from 2.68e-06\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  # Increased from 0.1\n",
    "    'reg_lambda': 5,  # Increased from 1\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'iterations': 200,\n",
    "    'random_seed': SEED,\n",
    "    'cat_features': cat_c,\n",
    "    'verbose': 0,\n",
    "    'l2_leaf_reg': 10  # Increase this value\n",
    "}\n",
    "\n",
    "# Create model instances\n",
    "Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model)\n",
    "])\n",
    "\n",
    "# Train the ensemble model\n",
    "Submission2 = TrainML(voting_model, test)\n",
    "\n",
    "# Save submission\n",
    "#Submission2.to_csv('submission.csv', index=False)\n",
    "Submission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    1\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    1\n",
       "5   001f3379    1\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    0\n",
       "10  0087dd65    0\n",
       "11  00abe655    0\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = Submission\n",
    "sub2 = Submission2\n",
    "\n",
    "sub1 = sub1.sort_values(by='id').reset_index(drop=True)\n",
    "sub2 = sub2.sort_values(by='id').reset_index(drop=True)\n",
    "\n",
    "combined = pd.DataFrame({\n",
    "    'id': sub1['id'],\n",
    "    'sii_1': sub1['sii'],\n",
    "    'sii_2': sub2['sii']\n",
    "})\n",
    "\n",
    "def majority_vote(row):\n",
    "    return row.mode()[0]\n",
    "\n",
    "combined['final_sii'] = combined[['sii_1', 'sii_2']].apply(majority_vote, axis=1)\n",
    "\n",
    "final_submission = combined[['id', 'final_sii']].rename(columns={'final_sii': 'sii'})\n",
    "\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
